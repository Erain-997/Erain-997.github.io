---
layout:     post
title:      压测-全链路压测
subtitle:   浅谈
date:       2022-06-20
author:     Erain
header-img: img/home-bg.jpg
categories: None
catalog: true
tags:
- 压测

---

参考资料：

- [阿里全链路压测](https://my.oschina.net/cctester/blog/994727)
- [有赞全链路压测](https://mp.weixin.qq.com/s/0a-Sd_fCkE2mDFzNpKxf7A)
- [京东全链路压测](https://www.sdk.cn/details/lE5wmb52qGDW8DgojN)
- [滴滴全链路压测解决之道](https://blog.csdn.net/g6u8w7p06dco99fq3/article/details/79119269)
- [美团全链路压测自动化实践](https://www.sdk.cn/details/vRw1ZkdWe4WL8amByJ)
- [逻辑思维在全链路压测方面的实践](https://www.toutiao.com/i6660639134580736526)
- [老张聊聊全链路压测](https://www.cnblogs.com/imyalost/p/8439910.html)

# 什么是全链路压测

基于实际的生产业务场景、系统环境，模拟海量的用户请求和数据对整个业务链进行压力测试，对整个业务链路进行各种业务场景的测试验证，并持续调优的过程。

全链路的压测应该尽量接近线上环境、线上实际使用场景。

# 为什么要全链路压测

首先应该明确的是：全链路压测针对的是现代越来越复杂的业务场景和全链路的系统依赖。所以首先应该将核心业务和非核心业务进行拆分，确认流量高峰针对的是哪些业务场景和模块，针对性的进行扩容准备，而不是为了解决海量流量冲击而所有的系统服务集群扩容几十倍，这样会造成不必要的成本投入。

主要为了解决：业务场景越发复杂化、海量数据冲击下整个业务系统链的可用性、服务能力的瓶颈，特别是微服务之间的瓶颈，在单独的接口测试中较难发现。让技术更好的服务业务，创造更多的价值。

| 传统压测 | 传统压测 | 全链路压测 |
| ---- | ---- | ---- |
| 压测方式 | Jmeter、Locust、Loadrunner | 压测集群、流量引擎、录制回放<br />开源：Takin <br />阿里：Amazon，PTS <br />美团：Quake <br />京东：ForceBOT <br />高德：TestPG <br />字节：Rhino |
| 承接方式 | 需求响应式，被动 | 发现系统所有链路存在的瓶颈点，主动 |
| 压测环境 | 测试环境/压测环境                                            | 生产环境、压测环境 |
| 环境特点 | 环境不稳定，容易受到开发影响，环境切换麻烦；<br />压测结果对于实际情况参考性不高 | 环境稳定，完全真实环境，压测结果真实可靠                     |
| 压测场景 | 单服务(接口/功能测试)；单机单链路测试 | 单接口测试可以覆盖到全链路，多接口可以覆盖大部分奇怪场景 |
| 压测结果 | 数据维度小，覆盖面较低，需要基于结果二次分析才能给结论。优点是对于问题的定位较快。 | 维度高。测试结果可直接用于结论。缺点是问题定位较困难。 |
| 投入成本 | 压测前需要确认环境(或搭建或数据隔离) | 需要搭建直接复用线上的压测环境，也可以直接复用线上环境(但是要注意脏数据) |

# 全链路压测的方案制定

## 压测目标

1. 单服务的瓶颈
1. 全链路瓶颈
1. 支持的各个参数量级
1. 稳定性、抗干扰性

## 压测方案梳理

1. **确定环境**         
   一般是基于生产环境，如果不能使用生产环境，则应尽量同线上环境，配置、服务架构保持一致或等倍。同时考虑扩容、容灾和风险规避策略。
   ps.小心起见，长远项目还是独立布置pet环境，使用集群式压测，复用环境快，独立，缺点是成本高。可以避免很多问题：
    1. 不需要压测标记。在出现问题时可以独立定位问题，方便数据的修复和验收。
    1. 压测流程自由。可以独立的进行压测和环境切换。
    1. 压测数据和实际生产环境数据不会污染，且可以独立用于线上数据的修复与验收。
1. **确定服务间通信**
    1. 确认同步、异步
    2. 确认通信协议
    3. 负载均衡：被测服务的均衡、压力机的均衡
    4. 容灾：当服务中的某台或者某部分服务宕机（常见的有oom，死锁，配置），可以及时的进行服务转发，而不至于连锁反应下整个系统链路的服务挂掉
1. **确定数据源**
    1. 真实的数据，基于线上数据/模拟数据
    1. 数据脱敏
    1. 数据隔离：为了避免造成脏数据写入，可以考虑通过压测数据隔离处理，落入影子库，mock对象等手段，来防止数据污染；
1. **确定压测工具** 
   全链路压测应对的都是海量的用户请求冲击，可以使用分布式压测的手段来进行用户请求模拟，目前有很多的开源工具可以提供分布式压测的方式，比如jmeter、Ngrinder、locust等。
   可以基于这些压测工具进行二次开发，由Contorller机器负责请求分发，agent机器进行压测，然后测试结果上传Contorller机器。
   考虑到压测量较大的情况下回传测试结果会对agent本身造成一定资源占用，可以考虑异步上传，甚至事务补偿机制。
1. **确定系统容量规划** 
   系统容量规划阶段，首先应该对单个接口单个服务进行基准测试，调整配置参数，得到一个基准线，然后进行分布式集群部署，通过nginx负载均衡。 至于扩容，要考虑到服务扩容和DB资源扩容，以及服务扩容带来的递减效应。
   至于大流量冲击情况下，可以考虑队列等待、容器锁、长连接回调、事务降级等方式来解决。遇事不决交给中台处理，搭建可多项目复用的k8s平台。
1. **确定数据监控与采集**
    1. 对于被压测服务：压测数据收集，需要由agent机回送给Contorller机器，但数据量过大会占用一定的资源，可以考虑异步实现测试结果回送。
    2. 对于压测服务：数据采集kibana+ES。

# 各个组件的瓶颈总结

todo